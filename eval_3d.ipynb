{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/depot/bera89/apps/giorom/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from models.config import TimeStepperConfig\n",
    "import torch\n",
    "from data import OneStepDataset, RolloutDataset\n",
    "from huggingface_hub import hf_hub_download, snapshot_download\n",
    "import random\n",
    "from random import randint\n",
    "from models.giorom3d_T import PhysicsEngine\n",
    "from utils.utils import oneStepMSE, rolloutMSE, visualize_graph\n",
    "import yaml\n",
    "#from Baselines.GAT import PhysicsEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "with open('configs/configs_nclaw_Plasticine_T.yaml', 'r') as f:\n",
    "        params = yaml.full_load(f)\n",
    "params = Namespace(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 128, 'n_mp_layers': 2, 'num_particle_types': 9, 'particle_type_dim': 16, 'dim': 3, 'window_size': 5, 'heads': 3, 'use_open3d': False, 'in_gno_mlp_hidden_layers': [131, 32, 64, 64], 'in_gno_transform_type': 'nonlinear_kernelonly', 'out_gno_in_dim': 3, 'out_gno_hidden': 128, 'out_gno_mlp_hidden_layers': [3, 32, 64, 128], 'out_gno_transform_type': 'linear', 'gno_radius': 0.165, 'not_heads': 4, 'not_layers': 1, 'not_output_size': 128, 'not_space_dim': 64, 'not_branch_size': 3, 'not_trunk_size': 64, 'projection_channels': 256, 'projection_layers': 1, 'projection_n_dim': 1, 'latent_grid_dim': 16, 'latent_domain_lims': [[0.0, 1.0], [0.0, 1.0], [0.0, 1.0]]}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if(params.model_config is not None):\n",
    "    if(params.model_config.endswith('.yaml') == False):\n",
    "        params.model_config += '.yaml'\n",
    "    model_config_path = os.path.join(os.getcwd(), 'configs', params.model_config)\n",
    "    if(os.path.exists(model_config_path) == False):\n",
    "        raise Exception(\"Invalid Model config path\")\n",
    "    with open(model_config_path, 'r') as f:\n",
    "        model_config = yaml.full_load(f)\n",
    "else:\n",
    "    raise Exception(\"Please provide a Model Config\")\n",
    "    \n",
    "\n",
    "print(model_config)\n",
    "time_stepper_config = TimeStepperConfig(**model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Loading Dataset...\n"
     ]
    }
   ],
   "source": [
    "print(\"...Loading Dataset...\")\n",
    "materials = {\"Water2D\":\"WaterDrop2DSmall\", \"Water3D\":\"Water3DNCLAWSmall\", \n",
    "             \"Water3D_long\":\"Water3DNCLAWSmall_longer_duration\", \"Sand2D\":\"Sand2DSmall\", \n",
    "             \"Sand3D\":\"Sand3DNCLAWSmall\", \"Sand3D_long\":\"Sand3DNCLAWSmall_longer_duration\", \n",
    "             \"MultiMaterial2D\":\"MultiMaterial2DSmall\", \"Plasticine3D\":\"Plasticine3DNCLAW\", \n",
    "             \"Elasticity3D\":\"Elasticity3DSmall\", \"Jelly3D\":\"Jelly3DNCLAWSmall\", \"RigidCollision3D\":\"RigidCollision3DNCLAWSmall\", \n",
    "             \"Melting3D\":\"Melting3DSampleSeq\"}\n",
    "\n",
    "if(params.dataset in materials.keys()):\n",
    "    if('2D' in params.dataset):\n",
    "        files = ['train.pt', 'test.pt', 'rollout.pt', 'metadata.json']\n",
    "        train_dir = hf_hub_download(repo_id=params.dataset_rootdir, repo_type='dataset', filename=os.path.join(materials[params.dataset], files[0]), cache_dir=\"./dataset_mpmverse\")\n",
    "        test_dir = hf_hub_download(repo_id=params.dataset_rootdir, repo_type='dataset', filename=os.path.join(materials[params.dataset], files[1]), cache_dir=\"./dataset_mpmverse\")\n",
    "        rollout_dir = hf_hub_download(repo_id=params.dataset_rootdir, repo_type='dataset', filename=os.path.join(materials[params.dataset], files[2]), cache_dir=\"./dataset_mpmverse\")\n",
    "        metadata_dir = hf_hub_download(repo_id=params.dataset_rootdir, repo_type='dataset', filename=os.path.join(materials[params.dataset], files[3]), cache_dir=\"./dataset_mpmverse\")\n",
    "    else:\n",
    "        files = ['train.obj', 'test.obj', 'rollout.obj', 'metadata.json', 'rollout_full.obj']\n",
    "        train_dir = hf_hub_download(repo_id=params.dataset_rootdir, repo_type='dataset', filename=os.path.join(materials[params.dataset], files[0]), cache_dir=\"./dataset_mpmverse\")\n",
    "        test_dir = hf_hub_download(repo_id=params.dataset_rootdir, repo_type='dataset', filename=os.path.join(materials[params.dataset], files[1]), cache_dir=\"./dataset_mpmverse\")\n",
    "        rollout_dir = hf_hub_download(repo_id=params.dataset_rootdir, repo_type='dataset', filename=os.path.join(materials[params.dataset], files[2]), cache_dir=\"./dataset_mpmverse\")\n",
    "        metadata_dir = hf_hub_download(repo_id=params.dataset_rootdir, repo_type='dataset', filename=os.path.join(materials[params.dataset], files[3]), cache_dir=\"./dataset_mpmverse\")\n",
    "        rollout_full_dir = hf_hub_download(repo_id=params.dataset_rootdir, repo_type='dataset', filename=os.path.join(materials[params.dataset], files[4]), cache_dir=\"./dataset_mpmverse\")\n",
    "else:\n",
    "    raise Exception(\"Dataset Name Invalid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric as pyg\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_dataset = OneStepDataset(train_dir, metadata_dir, noise_std=params.noise, sampling_strategy=params.sampling, graph_type=params.graph_type,radius=params.connectivity_radius)\n",
    "valid_dataset = OneStepDataset(test_dir, metadata_dir, noise_std=params.noise, sampling_strategy=params.sampling, graph_type=params.graph_type,radius=params.connectivity_radius)\n",
    "rollout_dataset = RolloutDataset(rollout_dir, metadata_dir, sampling_strategy=params.sampling, graph_type=params.graph_type,radius=params.connectivity_radius, mesh_size=170)[42:]\n",
    "train_loader = pyg.loader.DataLoader(train_dataset, batch_size=params.batch_size, shuffle=True)\n",
    "valid_loader = pyg.loader.DataLoader(valid_dataset, batch_size=params.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Linear Attention\n",
      "Number of parameters: 2387669\n",
      "Using Linear Attention\n",
      "Loaded Checkpoint\n"
     ]
    }
   ],
   "source": [
    "checkpoint_directory = os.path.join(os.getcwd(), 'saved_models')\n",
    "if(os.path.exists(checkpoint_directory) == False):\n",
    "    os.mkdir(checkpoint_directory)\n",
    "if(params.load_checkpoint == True):\n",
    "    if(params.ckpt_name is None):\n",
    "        raise Exception(\"No checkpoint Name specified\")\n",
    "    checkpoint = os.path.join(checkpoint_directory, params.ckpt_name)\n",
    "    if(os.path.exists(checkpoint)==False):\n",
    "        raise Exception(\"Invalid Checkpoint Directory\")\n",
    "simulator = PhysicsEngine(time_stepper_config)\n",
    "    \n",
    "optimizer = torch.optim.Adamax(simulator.parameters(), lr=params.lr, weight_decay=1e-6)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=eval(params.gamma))\n",
    "\n",
    "total_params = sum(p.numel() for p in simulator.parameters())\n",
    "print(f\"Number of parameters: {total_params}\")\n",
    "\n",
    "if(params.load_checkpoint):\n",
    "    if('.pt' in checkpoint):\n",
    "        ckpt = torch.load(checkpoint)\n",
    "        weights = torch.load(checkpoint)['model']\n",
    "\n",
    "        model_dict = simulator.state_dict()\n",
    "        ckpt_dict = {}\n",
    "        \n",
    "        \n",
    "        model_dict = dict(model_dict)\n",
    "\n",
    "        for k, v in weights.items():\n",
    "            k2 = k[0:]\n",
    "            \n",
    "            if k2 in model_dict:\n",
    "                \n",
    "                if model_dict[k2].size() == v.size():\n",
    "                    ckpt_dict[k2] = v\n",
    "                else:\n",
    "                    print(\"Size mismatch while loading! %s != %s Skipping %s...\"%(str(model_dict[k2].size()), str(v.size()), k2))\n",
    "                    mismatch = True\n",
    "            else:\n",
    "                print(\"Model Dict not in Saved Dict! %s != %s Skipping %s...\"%(2, str(v.size()), k2))\n",
    "                mismatch = True\n",
    "        if len(simulator.state_dict().keys()) > len(ckpt_dict.keys()):\n",
    "            print(\"SIZE MISMATCH\")\n",
    "            mismatch = True\n",
    "        model_dict.update(ckpt_dict)\n",
    "        simulator.load_state_dict(model_dict)\n",
    "        simulator = simulator.to(device)\n",
    "    else:\n",
    "        model_config = time_stepper_config.from_pretrained(checkpoint)\n",
    "        simulator = simulator.from_pretrained(checkpoint, config=model_config)\n",
    "        simulator = simulator.to(device)\n",
    "        optimizer_checkpoint = torch.load(checkpoint+'/optimizer.pt')\n",
    "        optimizer.load_state_dict(optimizer_checkpoint)\n",
    "        scheduler_checkpoint = torch.load(checkpoint+'/scheduler.pt')\n",
    "        scheduler.load_state_dict(scheduler_checkpoint)\n",
    "    print(\"Loaded Checkpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from utils.data_utils import preprocess\n",
    "def rollout(model, data, metadata, noise_std):\n",
    "    device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "    window_size = model.config.window_size + 1\n",
    "    total_time = data[\"position\"].size(0)\n",
    "    #total_time = 400\n",
    "    #print(\"Total Time = \", total_time)\n",
    "    \n",
    "    traj = data[\"position\"][:window_size]\n",
    "    #print(\"TRAJ SHAPE = \", traj.shape)\n",
    "    traj = traj.permute(1, 0, 2)\n",
    "    particle_type = data[\"particle_type\"]\n",
    "\n",
    "\n",
    "    for time in range(total_time - window_size):\n",
    "        print(time)\n",
    "        with torch.no_grad():\n",
    "            #print(\"PARTICLE TYPE = \", particle_type.shape)\n",
    "            #print(\"TRAJECTORY = \", traj.shape)\n",
    "            graph = preprocess(particle_type, traj[:, -window_size:], None, metadata, 0.0)\n",
    "            graph = graph.to(device)\n",
    "            acceleration = model(graph).cpu()\n",
    "            acceleration = acceleration * torch.sqrt(torch.tensor(metadata[\"acc_std\"]) ** 2 + noise_std ** 2) + torch.tensor(metadata[\"acc_mean\"])\n",
    "\n",
    "            recent_position = traj[:, -1]\n",
    "            recent_velocity = recent_position - traj[:, -2]\n",
    "            new_velocity = recent_velocity + acceleration\n",
    "            new_position = recent_position + new_velocity\n",
    "            traj = torch.cat((traj, new_position.unsqueeze(1)), dim=1)\n",
    "    return traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 2600, 3])\n",
      "torch.Size([2600])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 24\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#rollout_data_full = rollout_full[sim_id]\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#print(rollout_data_full['position'].shape)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m temp \u001b[38;5;241m=\u001b[39m rollout_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 24\u001b[0m rollout_out \u001b[38;5;241m=\u001b[39m \u001b[43mrollout\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimulator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrollout_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrollout_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnoise\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m rollout_out \u001b[38;5;241m=\u001b[39m rollout_out\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     26\u001b[0m loss \u001b[38;5;241m=\u001b[39m (rollout_out \u001b[38;5;241m-\u001b[39m rollout_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "Cell \u001b[0;32mIn[10], line 22\u001b[0m, in \u001b[0;36mrollout\u001b[0;34m(model, data, metadata, noise_std)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m#print(\"PARTICLE TYPE = \", particle_type.shape)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m#print(\"TRAJECTORY = \", traj.shape)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     graph \u001b[38;5;241m=\u001b[39m preprocess(particle_type, traj[:, \u001b[38;5;241m-\u001b[39mwindow_size:], \u001b[38;5;28;01mNone\u001b[39;00m, metadata, \u001b[38;5;241m0.0\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m     graph \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     acceleration \u001b[38;5;241m=\u001b[39m model(graph)\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     24\u001b[0m     acceleration \u001b[38;5;241m=\u001b[39m acceleration \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(torch\u001b[38;5;241m.\u001b[39mtensor(metadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macc_std\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m noise_std \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(metadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macc_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m/depot/bera89/apps/giorom/lib/python3.10/site-packages/torch_geometric/data/data.py:362\u001b[0m, in \u001b[0;36mBaseData.to\u001b[0;34m(self, device, non_blocking, *args)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    358\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/depot/bera89/apps/giorom/lib/python3.10/site-packages/torch_geometric/data/data.py:342\u001b[0m, in \u001b[0;36mBaseData.apply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m store \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstores:\n\u001b[0;32m--> 342\u001b[0m     \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/depot/bera89/apps/giorom/lib/python3.10/site-packages/torch_geometric/data/storage.py:201\u001b[0m, in \u001b[0;36mBaseStorage.apply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems(\u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;241m=\u001b[39m \u001b[43mrecursive_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/depot/bera89/apps/giorom/lib/python3.10/site-packages/torch_geometric/data/storage.py:897\u001b[0m, in \u001b[0;36mrecursive_apply\u001b[0;34m(data, func)\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrecursive_apply\u001b[39m(data: Any, func: Callable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Tensor):\n\u001b[0;32m--> 897\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mPackedSequence):\n\u001b[1;32m    899\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(data)\n",
      "File \u001b[0;32m/depot/bera89/apps/giorom/lib/python3.10/site-packages/torch_geometric/data/data.py:363\u001b[0m, in \u001b[0;36mBaseData.to.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    358\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m--> 363\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rollout_dataset = RolloutDataset(rollout_dir, metadata_dir, sampling_strategy=params.sampling, graph_type=params.graph_type,radius=params.connectivity_radius, mesh_size=170)\n",
    "rollout_dataset_gt = RolloutDataset(rollout_dir, metadata_dir, sampling_strategy=params.sampling, graph_type=params.graph_type,radius=params.connectivity_radius, mesh_size=170)\n",
    "#print(len(rollout_dataset))\n",
    "simulator.eval()\n",
    "sim_id = 0\n",
    "rollout_data = rollout_dataset[sim_id]\n",
    "if(rollout_data['position'].shape[1] != rollout_data['particle_type'].shape[0]):\n",
    "    temp = rollout_data['position']\n",
    "    temp = temp.permute(1, 0, 2)\n",
    "    temp = temp[:rollout_data['particle_type'].shape[0]]\n",
    "    temp = temp.permute(1, 0, 2)\n",
    "    rollout_data['position'] = temp\n",
    "print(rollout_data['position'].shape)\n",
    "print(rollout_data['particle_type'].shape)\n",
    "\n",
    "#rollout_data_gt = rollout_dataset_gt[1]\n",
    "rollout_data_gt = rollout_dataset_gt[sim_id]\n",
    "#rollout_data_full = rollout_full[sim_id]\n",
    "#print(rollout_data_full['position'].shape)\n",
    "temp = rollout_data['position'][0]\n",
    "\n",
    "\n",
    "\n",
    "rollout_out = rollout(simulator, rollout_data, rollout_dataset.metadata, params.noise)\n",
    "rollout_out = rollout_out.permute(1, 0, 2)\n",
    "loss = (rollout_out - rollout_data[\"position\"]) ** 2\n",
    "loss = loss.sum(dim=-1).mean()\n",
    "print(\"Rollout Loss: \", loss)\n",
    "#torch.save(rollout_out, f'outputs/{params[\"model\"]}_{params[\"dataset\"]}_{sim_id}.pt')\n",
    "#torch.save(rollout_data_full, f'outputs/{params[\"model\"]}_{params[\"dataset\"]}_{sim_id}_gt.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "TYPE_TO_COLOR = {\n",
    "    3: \"black\",\n",
    "    0: \"green\",\n",
    "    7: \"magenta\",\n",
    "    6: \"gold\",\n",
    "    5: \"blue\",\n",
    "}\n",
    "\n",
    "\n",
    "def visualize_prepare(ax, particle_type, position, metadata):\n",
    "    bounds = metadata[\"bounds\"]\n",
    "    ax.set_xlim(bounds[0][0], bounds[0][1])\n",
    "    ax.set_ylim(bounds[1][0], bounds[1][1])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_aspect(1.0)\n",
    "    points = {type_: ax.plot([], [], \"o\", ms=2, color=color)[0] for type_, color in TYPE_TO_COLOR.items()}\n",
    "    return ax, position, points\n",
    "\n",
    "\n",
    "def visualize_pair(particle_type, position_pred, position_gt, metadata):\n",
    "    print(position_pred.shape)\n",
    "    print(position_gt.shape)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    old_particle_type = torch.ones(size=(position_gt.shape[1],)) * particle_type[0]\n",
    "    plot_info = [\n",
    "        visualize_prepare(axes[0], old_particle_type, position_gt, metadata),\n",
    "        visualize_prepare(axes[1], particle_type, position_pred, metadata),\n",
    "    ]\n",
    "    axes[0].set_title(\"Ground truth\")\n",
    "    axes[1].set_title(\"Prediction\")\n",
    "\n",
    "    plt.close()\n",
    "    def update(step_i):\n",
    "        outputs = []\n",
    "        for _, position, points in plot_info:\n",
    "            for type_, line in points.items():\n",
    "                mask = particle_type == type_\n",
    "                if(position.shape[1] == position_gt.shape[1]):\n",
    "                    mask = old_particle_type == type_\n",
    "                    #print(position.shape, mask.shape)\n",
    "                #print(position.shape, mask.shape)\n",
    "                line.set_data(position[step_i, mask, 0], position[step_i, mask, 1])\n",
    "            outputs.append(line)\n",
    "        return outputs\n",
    "\n",
    "    return animation.FuncAnimation(fig, update, frames=np.arange(0, position_gt.size(0)), interval=20, blit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "#inp = torch.load('out.pt')\n",
    "#anim = visualize_pair(inp['pt'], inp['rout'], inp['pos'], inp['met'])\n",
    "#anim = visualize_pair(rollout_data[\"particle_type\"], rollout_out, rollout_data[\"position\"], rollout_dataset.metadata)\n",
    "anim = visualize_pair(rollout_data[\"particle_type\"], rollout_out, rollout_data_gt['position'], rollout_dataset.metadata)\n",
    "HTML(anim.to_html5_video())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
